n8n_scrapper

Prerequisites for the workflow to work:
1.An rss.app account with proper domain specific feeds
2.A Google Drive, Google Sheets and Google Gemini account with it's API key through google console
3.A Docker account, PostgreSQL Database
4.Cursor.ai for running the dashboard

To Run this workflow, create your RSS app feed for your RSS node 
Here are the steps you have to follow:-
1. First go to Google news for the feeds that we need for scraping
2. Choose from any field from the Google News Dashboard, eg. (World, Finance, Tecnology, Health, etc)
3. After choosing the field from Google News, copy the URL of the chosen field. (eg. https://news.google.com/topics/CAAqKggKIiRDQkFTRlFvSUwyMHZNRGRqTVhZU0JXVnVMVWRDR2dKSlRpZ0FQAQ?hl=en-IN&gl=IN&ceid=IN%3Aen)
4. Go to rss.app and click on the new feed button and paste the url into the field
5. After pasting the URL, hit generate to generate your custom domain specific RSS feed 
6. After genrating the feed, click on the Customize button under Feed Output, which shows on right side of the feed
7. Inside the Customize window, modify the field named "Number of Posts" and change it to 1 for the time being as to not hit the API limit of Firecrawl Scrape
8. After completing the previous step, you can now see the feed URL. Copy that URL and make sure that the extension is .XML, right next to the URl in the dropdown
9. Next, go to the n8n_scrapping workflow and paste the rss URL inside the RSS Read Node 
10.The RSS node is now setup and ready for execution

After completing and setting up the RSS node, the workflow now consists of an AI Agent and a Google Gemini chat node that is attached to the AI Agent in the tools section. Inside that Gemini model, you have to configure your Googe API and authenticate your account in order to access Google cloud console and it's services

The next crucial node is the Firecrawl HTTP Request node.
Here is the following steps to setup you firecrawl tool node :-
1. First, go to the FireCrawl Website(https://www.firecrawl.dev) and create an account.
2. After creating an account, go to the Dashboard, and create an API key from the "API Keys" section
3. After setting up your account and creating an API key, Come back to you n8n workflow and go into the FireCrawl Scraping tool node, then put your credentials into fields based on the documentation and the format FireCrawl has provided in the Docs section
4. Now your Firecrawl node is ready to scrape! 


Lets setup the Google sheet node, here are the steps to follow:-
1. Create a new Google Sheet 
2. Name that sheet according to your convenience
3. The headers of each column of the sheet should be in this format: 

Domain, Category, Title, articles, URL, trending_keywords, Publication_Date, cover_image, author_name.

4. Access the Google sheet node
4. Inside the node, connect it with you credentials 
5. Inside the node, find the section named "Document" and select "By ID".
6. Now, go back to the Google Sheet that you created and copy the characters after /d/. eg (//YOUR_GOOGLE_SHEET_URL/d/13PTK3jNdVlLE6PrND7p6lMl5YdwFxCjUzRt43C7IQgE)
6. After pasting the ID, below the "Document" section, find the column named "Sheet" and select "From List". 
7. Select the name of the sheet you created, and it will map all the columns from the previous node and export the data into your Google sheet. 

After this Set up, run the entire workflow as a whole, the process will look like this:

RSS Feed -> AI Agent -> Google Gemini -> fire crawl scrapper -> Code -> Append row in sheet

This workflow will now fetch the articles and data from rss.app and fetch it according to the Google sheet and paste it into the Google Sheet!








